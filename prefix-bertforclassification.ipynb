{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445},{"sourceId":10178011,"sourceType":"datasetVersion","datasetId":6286661},{"sourceId":10178255,"sourceType":"datasetVersion","datasetId":6286868},{"sourceId":212798112,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2695.631154,"end_time":"2024-12-13T04:05:51.106111","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-13T03:20:55.474957","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"009f932ab03a4bb998ed9523a36b24b9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063b3079825e4ba6bbc6b91e6124e60b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_77d1f16840fc4cb189c800c8721aa959","placeholder":"​","style":"IPY_MODEL_7a855567342b468eb821a425d197077e","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"06681b6c23844a909990d761633c7d4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"094ce54453fa4e59929ce2fd6c30a705":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af48179f38884e33978aec690ed81a83","IPY_MODEL_299f074b58bc4766b9562b7394a4c253","IPY_MODEL_bb9ab961dad242efb4ce255ec44ec334"],"layout":"IPY_MODEL_009f932ab03a4bb998ed9523a36b24b9","tabbable":null,"tooltip":null}},"0b337eaba19d41b6b1654fcce3ee5ce8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12fe6328b4fe4ae8a0708d41b5fb5c2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"154160b282e040d089736e8c084a93cd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1726b0ae2ba24a6595b668f66f83aade":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18bf8ae782d64781bce3f0e077efd5d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"1c03b85133814bfc9fb3ee93d20ceef9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f722e3ec969479d98251429f9dafdbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bf27813143634d6db6668af483cd3e69","placeholder":"​","style":"IPY_MODEL_e8f7ebd3783f40b9b738690111ddd656","tabbable":null,"tooltip":null,"value":" 213k/213k [00:00&lt;00:00, 3.16MB/s]"}},"1ff725bcbbc04ef4b16435e307523a5c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"210ac9636aa7416784c967b5d3319a8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8ff8648c313643c0a090e54dee5b3062","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21965eca91a343858223cbe68c3f22d3","tabbable":null,"tooltip":null,"value":213450}},"21965eca91a343858223cbe68c3f22d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2422b4354e4647f0b1f5899325f0687d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"299f074b58bc4766b9562b7394a4c253":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_7375472055934374a56315cf9a88df1f","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31ce4e4530c34a14a3eff5d3d2adb27c","tabbable":null,"tooltip":null,"value":49}},"2e96591c5b7f46fe86d93b246877dc7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa60c931525e4f4b856c09c03bafd0f1","IPY_MODEL_210ac9636aa7416784c967b5d3319a8d","IPY_MODEL_1f722e3ec969479d98251429f9dafdbd"],"layout":"IPY_MODEL_3db6287c3a214dc9bdb3bb3e0ab9688d","tabbable":null,"tooltip":null}},"31ce4e4530c34a14a3eff5d3d2adb27c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3db6287c3a214dc9bdb3bb3e0ab9688d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e8d90dd9151439189151f99e5a9a874":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53bb823ec9b045fab0b76be3e15c8120":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e36e949ebd43b1b9296d14e262a7c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"655ab615fa8b40989ee0ac1d5e1df479":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db830dda3ff40448fe33a20018d9659":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6f4aad8ddd18402d96968a3be7b5cfce":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_154160b282e040d089736e8c084a93cd","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7b8152595274b48a00c0d73d4ca340b","tabbable":null,"tooltip":null,"value":435755784}},"7375472055934374a56315cf9a88df1f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7451eb378b974d40be9d1346820c5bd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77d1f16840fc4cb189c800c8721aa959":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a855567342b468eb821a425d197077e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8ff8648c313643c0a090e54dee5b3062":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"910de079c407428595214d7e8bf09583":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa127912f7804efc837ede64bcd42493":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea1ab44273c246c6853bdec3f6231da2","IPY_MODEL_f4a72b4327a04d92a99eef8043792311","IPY_MODEL_cbb0136a8b544ea591d0476aacf960e2"],"layout":"IPY_MODEL_1726b0ae2ba24a6595b668f66f83aade","tabbable":null,"tooltip":null}},"aac1ba25be4a4122bf0dd3046b0a26a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af48179f38884e33978aec690ed81a83":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_655ab615fa8b40989ee0ac1d5e1df479","placeholder":"​","style":"IPY_MODEL_e6382534b81f4972a95ba52d07b82acc","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"b4627ce6af7e4b048568c002296d4505":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_063b3079825e4ba6bbc6b91e6124e60b","IPY_MODEL_6f4aad8ddd18402d96968a3be7b5cfce","IPY_MODEL_d1d565a8dd454e138f8646079f6cd784"],"layout":"IPY_MODEL_53bb823ec9b045fab0b76be3e15c8120","tabbable":null,"tooltip":null}},"b4bb54442ce2480080cd29404e04af5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d003fb6837504c1b81994802f74cc725","placeholder":"​","style":"IPY_MODEL_06681b6c23844a909990d761633c7d4f","tabbable":null,"tooltip":null,"value":" 570/570 [00:00&lt;00:00, 74.7kB/s]"}},"bb9ab961dad242efb4ce255ec44ec334":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c396203b60724bdf868aeb6a205c7b88","placeholder":"​","style":"IPY_MODEL_64e36e949ebd43b1b9296d14e262a7c3","tabbable":null,"tooltip":null,"value":" 49.0/49.0 [00:00&lt;00:00, 4.80kB/s]"}},"bf27813143634d6db6668af483cd3e69":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c317f5254e614411887773620502f3ea":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c396203b60724bdf868aeb6a205c7b88":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbb0136a8b544ea591d0476aacf960e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e94bb45c7869468398cc0f8ab15f5381","placeholder":"​","style":"IPY_MODEL_dbe4e2ddd6c44411837cfe95c3dfefef","tabbable":null,"tooltip":null,"value":" 436k/436k [00:00&lt;00:00, 3.61MB/s]"}},"d003fb6837504c1b81994802f74cc725":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1d565a8dd454e138f8646079f6cd784":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3e8d90dd9151439189151f99e5a9a874","placeholder":"​","style":"IPY_MODEL_18bf8ae782d64781bce3f0e077efd5d3","tabbable":null,"tooltip":null,"value":" 436M/436M [00:01&lt;00:00, 218MB/s]"}},"d6b06168996c4fd6ba737b24d4fb4cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d8b7537d289c4d51baf014ba68d36ea4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_1ff725bcbbc04ef4b16435e307523a5c","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aac1ba25be4a4122bf0dd3046b0a26a8","tabbable":null,"tooltip":null,"value":570}},"dbe4e2ddd6c44411837cfe95c3dfefef":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e6382534b81f4972a95ba52d07b82acc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e7b8152595274b48a00c0d73d4ca340b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8f7ebd3783f40b9b738690111ddd656":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e94bb45c7869468398cc0f8ab15f5381":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1ab44273c246c6853bdec3f6231da2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0b337eaba19d41b6b1654fcce3ee5ce8","placeholder":"​","style":"IPY_MODEL_d6b06168996c4fd6ba737b24d4fb4cea","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"f4a72b4327a04d92a99eef8043792311":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_910de079c407428595214d7e8bf09583","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7451eb378b974d40be9d1346820c5bd4","tabbable":null,"tooltip":null,"value":435797}},"fa49c172f4b744aba0ab93948397a0a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa58ac2af85e438f95cc59aa642e3330","IPY_MODEL_d8b7537d289c4d51baf014ba68d36ea4","IPY_MODEL_b4bb54442ce2480080cd29404e04af5a"],"layout":"IPY_MODEL_1c03b85133814bfc9fb3ee93d20ceef9","tabbable":null,"tooltip":null}},"fa58ac2af85e438f95cc59aa642e3330":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2422b4354e4647f0b1f5899325f0687d","placeholder":"​","style":"IPY_MODEL_12fe6328b4fe4ae8a0708d41b5fb5c2b","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"fa60c931525e4f4b856c09c03bafd0f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c317f5254e614411887773620502f3ea","placeholder":"​","style":"IPY_MODEL_6db830dda3ff40448fe33a20018d9659","tabbable":null,"tooltip":null,"value":"vocab.txt: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"74153289","cell_type":"code","source":"pip install transformers datasets torch scikit-learn pandas\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":9.33552,"end_time":"2024-12-13T03:21:07.208840","exception":false,"start_time":"2024-12-13T03:20:57.873320","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:01:51.004019Z","iopub.execute_input":"2024-12-21T03:01:51.004879Z","iopub.status.idle":"2024-12-21T03:01:59.127409Z","shell.execute_reply.started":"2024-12-21T03:01:51.004828Z","shell.execute_reply":"2024-12-21T03:01:59.126268Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"id":"15c4ac84-e2ba-467c-a908-dee37bc65524","cell_type":"markdown","source":"# Download dataset","metadata":{}},{"id":"0872314a-6121-487f-b58c-2172341d27b2","cell_type":"code","source":"import kagglehub\nimport pandas as pd\n\npath = kagglehub.dataset_download(\"abhi8923shriv/sentiment-analysis-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:01:59.129202Z","iopub.execute_input":"2024-12-21T03:01:59.129509Z","iopub.status.idle":"2024-12-21T03:01:59.665297Z","shell.execute_reply.started":"2024-12-21T03:01:59.129481Z","shell.execute_reply":"2024-12-21T03:01:59.664484Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/sentiment-analysis-dataset\n","output_type":"stream"}],"execution_count":11},{"id":"487dfbe9-dbc0-492a-915c-883610de5f73","cell_type":"code","source":"import pandas as pd\n\ncsv_path = path+\"/train.csv\"\ndata = pd.read_csv(csv_path, encoding='latin1')\nprint(\"\\nSố dòng trong mỗi cột:\")\nprint(len(data[['text', 'sentiment']]))\n\nprint(\"\\nSố dòng thiếu trong mỗi cột:\")\nprint(data[['text', 'sentiment']].isna().sum())\n\ndata_cleaned = data.dropna(subset=['text', 'sentiment'])\n\ndata_cleaned = data_cleaned[data_cleaned['text'].str.strip() != \"\"]\ndata_cleaned = data_cleaned[data_cleaned['sentiment'].str.strip() != \"\"]\n\ndata_cleaned.to_csv(\"cleaned_train.csv\", index=False)\n\n#================================================\n\ncsv_path = path+\"/test.csv\"\ndata = pd.read_csv(csv_path, encoding='latin1')\n\nprint(\"\\nSố dòng thiếu trong mỗi cột:\")\nprint(data[['text', 'sentiment']].isna().sum())\n\ndata_cleaned = data.dropna(subset=['text', 'sentiment'])\n\ndata_cleaned = data_cleaned[data_cleaned['text'].str.strip() != \"\"]\ndata_cleaned = data_cleaned[data_cleaned['sentiment'].str.strip() != \"\"]\n\ndata_cleaned.to_csv(\"cleaned_test.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:01:59.666322Z","iopub.execute_input":"2024-12-21T03:01:59.666622Z","iopub.status.idle":"2024-12-21T03:02:00.019609Z","shell.execute_reply.started":"2024-12-21T03:01:59.666595Z","shell.execute_reply":"2024-12-21T03:02:00.018573Z"}},"outputs":[{"name":"stdout","text":"\nSố dòng trong mỗi cột:\n27481\n\nSố dòng thiếu trong mỗi cột:\ntext         1\nsentiment    0\ndtype: int64\n\nSố dòng thiếu trong mỗi cột:\ntext         1281\nsentiment    1281\ndtype: int64\n","output_type":"stream"}],"execution_count":12},{"id":"556d2efa","cell_type":"code","source":"import pandas as pd\n\n# Đọc file CSV\ndf = pd.read_csv('/kaggle/working/cleaned_train.csv', encoding='latin-1')  \ntdf = pd.read_csv('/kaggle/working/cleaned_test.csv', encoding='latin-1')\n\nprint(df.head())\n\nprint(df.columns)\n\ndf = df[['text', 'sentiment']]\ntdf = tdf[['text', 'sentiment']]\n\ndef convert_sentiment_label(x):\n    if x == 'positive':\n        return 1\n    elif x == 'negative':\n        return 0\n    else:\n        return 2\n\ndf['sentiment'] = df['sentiment'].apply(convert_sentiment_label)\ntdf['sentiment'] = tdf['sentiment'].apply(convert_sentiment_label)\n\ndf['text'] = df['text'].astype(str)\ntdf['text'] = tdf['text'].astype(str)\n\ntrain_texts = df['text']\ntrain_labels = df['sentiment']\nval_texts= tdf['text']\nval_labels = tdf['sentiment']\n\nprint(\"Train size:\", len(train_texts))\nprint(\"Test size:\", len(val_texts))","metadata":{"papermill":{"duration":0.898736,"end_time":"2024-12-13T03:21:08.110457","exception":false,"start_time":"2024-12-13T03:21:07.211721","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:02:00.022243Z","iopub.execute_input":"2024-12-21T03:02:00.022642Z","iopub.status.idle":"2024-12-21T03:02:00.158045Z","shell.execute_reply.started":"2024-12-21T03:02:00.022589Z","shell.execute_reply":"2024-12-21T03:02:00.157159Z"}},"outputs":[{"name":"stdout","text":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment Time of Tweet Age of User  \\\n0  I`d have responded, if I were going   neutral       morning        0-20   \n1                             Sooo SAD  negative          noon       21-30   \n2                          bullying me  negative         night       31-45   \n3                       leave me alone  negative       morning       46-60   \n4                        Sons of ****,  negative          noon       60-70   \n\n       Country  Population -2020  Land Area (KmÂ²)  Density (P/KmÂ²)  \n0  Afghanistan          38928346          652860.0                60  \n1      Albania           2877797           27400.0               105  \n2      Algeria          43851044         2381740.0                18  \n3      Andorra             77265             470.0               164  \n4       Angola          32866272         1246700.0                26  \nIndex(['textID', 'text', 'selected_text', 'sentiment', 'Time of Tweet',\n       'Age of User', 'Country', 'Population -2020', 'Land Area (KmÂ²)',\n       'Density (P/KmÂ²)'],\n      dtype='object')\nTrain size: 27480\nTest size: 3534\n","output_type":"stream"}],"execution_count":13},{"id":"90453d78","cell_type":"code","source":"from transformers import BertTokenizer, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\nprint(\"Tokenizer loaded successfully!\")\n\ndef tokenize_function(texts):\n    return tokenizer(texts, padding='max_length', truncation=True, max_length=220, return_tensors=\"pt\")\n\ntrain_encodings = tokenize_function(list(train_texts))\nval_encodings = tokenize_function(list(val_texts))\n","metadata":{"papermill":{"duration":14.781094,"end_time":"2024-12-13T03:21:22.894256","exception":false,"start_time":"2024-12-13T03:21:08.113162","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:02:53.356250Z","iopub.execute_input":"2024-12-21T03:02:53.356696Z","iopub.status.idle":"2024-12-21T03:02:59.120121Z","shell.execute_reply.started":"2024-12-21T03:02:53.356653Z","shell.execute_reply":"2024-12-21T03:02:59.118964Z"}},"outputs":[{"name":"stdout","text":"Tokenizer loaded successfully!\n","output_type":"stream"}],"execution_count":19},{"id":"a6efd630","cell_type":"code","source":"import torch\n\nclass SentimentDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\ntrain_dataset = SentimentDataset(train_encodings, train_labels)\nval_dataset = SentimentDataset(val_encodings, val_labels)\nprint('run complete')\n","metadata":{"papermill":{"duration":0.016251,"end_time":"2024-12-13T03:21:22.915710","exception":false,"start_time":"2024-12-13T03:21:22.899459","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:03:18.705639Z","iopub.execute_input":"2024-12-21T03:03:18.705996Z","iopub.status.idle":"2024-12-21T03:03:19.116793Z","shell.execute_reply.started":"2024-12-21T03:03:18.705965Z","shell.execute_reply":"2024-12-21T03:03:19.115952Z"}},"outputs":[{"name":"stdout","text":"run complete\n","output_type":"stream"}],"execution_count":20},{"id":"2829b0f3-6f14-49e2-81b2-22651fafd239","cell_type":"code","source":"!pip install --upgrade peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:02:06.660824Z","iopub.execute_input":"2024-12-21T03:02:06.661163Z","iopub.status.idle":"2024-12-21T03:02:14.962694Z","shell.execute_reply.started":"2024-12-21T03:02:06.661127Z","shell.execute_reply":"2024-12-21T03:02:14.961510Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.14.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (1.1.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.26.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (2024.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}],"execution_count":16},{"id":"684c007c","cell_type":"code","source":"from peft import PrefixEncoder, PrefixTuningConfig, get_peft_model\nfrom transformers import BertForSequenceClassification\nimport torch\nfrom torch import nn\nimport os\n\nconfig = PrefixTuningConfig(\n    peft_type=\"PREFIX_TUNING\",\n    task_type=\"SEQ_CLS\",\n    num_virtual_tokens=100,\n    token_dim=1024,\n    num_transformer_submodules=1,\n    num_attention_heads=16,\n    encoder_hidden_size=1024 \n)\n\ndef defineNewModel(config = config):\n    base_model = BertForSequenceClassification.from_pretrained(\n            \"bert-large-uncased\", num_labels=3)\n\n    prefix_model = get_peft_model(base_model, config)\n    prefix_model.print_trainable_parameters()\n    return prefix_model","metadata":{"papermill":{"duration":14.995537,"end_time":"2024-12-13T03:21:37.914233","exception":false,"start_time":"2024-12-13T03:21:22.918696","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:03:26.498584Z","iopub.execute_input":"2024-12-21T03:03:26.498934Z","iopub.status.idle":"2024-12-21T03:03:26.504858Z","shell.execute_reply.started":"2024-12-21T03:03:26.498905Z","shell.execute_reply":"2024-12-21T03:03:26.503903Z"}},"outputs":[],"execution_count":21},{"id":"205b4011","cell_type":"code","source":"from torch.nn import CrossEntropyLoss\nfrom torch import cuda\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nfrom tqdm import tqdm\nimport time\nimport random\nfrom torch.utils.data import Subset\nfrom sklearn.metrics import accuracy_score\nfrom transformers import BertForSequenceClassification, DistilBertForSequenceClassification\nfrom collections import Counter\n\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndata_len_list = [100, 200, 300, 400, 500, 1000, 10000]\nepochs = 10\nbatch_size = 32\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\ndef EvalModel(model):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=-1)\n            all_preds.extend(predictions.cpu().numpy())\n            all_labels.extend(batch['labels'].cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Validation Trained Model Accuracy: {accuracy:.4f}\")\n    print(\"===========================================\")\n\n# Training for many data_length\nfor data_length in data_len_list:\n    model = defineNewModel()\n\n    for name,param in model.named_parameters():\n        if param.requires_grad==True:\n            print(\"Traing Param: \", name)\n\n    model.to(device)\n    model.train()\n    print(\"Training Data Length: \", data_length)\n    # Create random indices\n    random_indices = random.sample(range(len(train_dataset)), data_length)\n    train_subset = Subset(train_dataset, random_indices)\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n    optimizer = AdamW(model.parameters(), lr=5e-4)\n    \n    label_counts = Counter()\n    for batch in train_loader:\n        labels = batch['labels']\n        label_counts.update(labels.tolist())\n    for label, count in label_counts.items():\n        print(f\"Label {label}: {count} samples\")\n\n    for epoch in range(epochs):\n        start_time = time.time()\n        total_loss = 0\n        correct_predictions = 0\n        total_samples = 0\n        for batch in train_loader:\n            optimizer.zero_grad()\n            batch = {k: v.to(device) for k, v in batch.items()}\n            labels = batch[\"labels\"]\n            outputs = model(**batch)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_predictions += torch.sum(preds == labels).item()\n            total_samples += labels.size(0)\n        epoch_time = time.time() - start_time\n        avg_loss = total_loss / len(train_loader)\n        accuracy = correct_predictions / total_samples * 100\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}, \"\n              f\"Accuracy: {correct_predictions / total_samples:.4f}, \"\n              f\"Time: {epoch_time:.2f} seconds\")\n\n    # Eval model =====================================================\n    EvalModel(model)\n\n\n    \n\n","metadata":{"papermill":{"duration":2632.507881,"end_time":"2024-12-13T04:05:30.425529","exception":false,"start_time":"2024-12-13T03:21:37.917648","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:03:35.907749Z","iopub.execute_input":"2024-12-21T03:03:35.908727Z","execution_failed":"2024-12-21T03:37:48.286Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  100\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Label 2: 48 samples\nLabel 0: 34 samples\nLabel 1: 18 samples\nEpoch 1/10, Loss: 1.066273808479309, Accuracy: 0.5300, Time: 5.49 seconds\nEpoch 2/10, Loss: 1.164434552192688, Accuracy: 0.4500, Time: 4.86 seconds\nEpoch 3/10, Loss: 1.1195420026779175, Accuracy: 0.4500, Time: 4.87 seconds\nEpoch 4/10, Loss: 0.9903809875249863, Accuracy: 0.4800, Time: 4.87 seconds\nEpoch 5/10, Loss: 1.0555797219276428, Accuracy: 0.4600, Time: 4.86 seconds\nEpoch 6/10, Loss: 0.9894406348466873, Accuracy: 0.4800, Time: 4.87 seconds\nEpoch 7/10, Loss: 0.9628000259399414, Accuracy: 0.4400, Time: 4.86 seconds\nEpoch 8/10, Loss: 1.066466599702835, Accuracy: 0.4600, Time: 4.86 seconds\nEpoch 9/10, Loss: 1.0548924803733826, Accuracy: 0.4700, Time: 4.87 seconds\nEpoch 10/10, Loss: 1.063894808292389, Accuracy: 0.4900, Time: 4.87 seconds\nValidation Trained Model Accuracy: 0.3698\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  200\nLabel 1: 58 samples\nLabel 0: 59 samples\nLabel 2: 83 samples\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.155322756086077, Accuracy: 0.3750, Time: 9.74 seconds\nEpoch 2/10, Loss: 1.0965702789170402, Accuracy: 0.3950, Time: 9.75 seconds\nEpoch 3/10, Loss: 1.1438770634787423, Accuracy: 0.3600, Time: 9.75 seconds\nEpoch 4/10, Loss: 1.1044908591679163, Accuracy: 0.3950, Time: 9.76 seconds\nEpoch 5/10, Loss: 1.1050937856946672, Accuracy: 0.3350, Time: 9.77 seconds\nEpoch 6/10, Loss: 1.1088108164923531, Accuracy: 0.3400, Time: 9.76 seconds\nEpoch 7/10, Loss: 1.1170735188892909, Accuracy: 0.4300, Time: 9.76 seconds\nEpoch 8/10, Loss: 1.0895420483180456, Accuracy: 0.3700, Time: 9.77 seconds\nEpoch 9/10, Loss: 1.0914222853524345, Accuracy: 0.4050, Time: 9.76 seconds\nEpoch 10/10, Loss: 1.0955942869186401, Accuracy: 0.4150, Time: 9.76 seconds\nValidation Trained Model Accuracy: 0.4029\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  300\nLabel 1: 108 samples\nLabel 0: 85 samples\nLabel 2: 107 samples\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.1210111916065215, Accuracy: 0.3767, Time: 14.63 seconds\nEpoch 2/10, Loss: 1.0967368602752685, Accuracy: 0.3833, Time: 14.65 seconds\nEpoch 3/10, Loss: 1.0869870901107788, Accuracy: 0.3500, Time: 14.65 seconds\nEpoch 4/10, Loss: 1.0824952006340027, Accuracy: 0.3633, Time: 14.66 seconds\nEpoch 5/10, Loss: 1.0726159930229187, Accuracy: 0.4067, Time: 14.66 seconds\nEpoch 6/10, Loss: 1.0482067823410035, Accuracy: 0.4300, Time: 14.67 seconds\nEpoch 7/10, Loss: 1.0281359076499939, Accuracy: 0.4567, Time: 14.67 seconds\nEpoch 8/10, Loss: 1.069911140203476, Accuracy: 0.3967, Time: 14.66 seconds\nEpoch 9/10, Loss: 1.0424272179603578, Accuracy: 0.4633, Time: 14.66 seconds\nEpoch 10/10, Loss: 1.0292122185230255, Accuracy: 0.4167, Time: 14.66 seconds\nValidation Trained Model Accuracy: 0.4233\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  400\nLabel 1: 124 samples\nLabel 0: 111 samples\nLabel 2: 165 samples\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.115982202383188, Accuracy: 0.3725, Time: 19.47 seconds\nEpoch 2/10, Loss: 1.1339696829135602, Accuracy: 0.3500, Time: 19.50 seconds\nEpoch 3/10, Loss: 1.075575094956618, Accuracy: 0.4000, Time: 19.49 seconds\nEpoch 4/10, Loss: 1.075582430912898, Accuracy: 0.3875, Time: 19.48 seconds\nEpoch 5/10, Loss: 1.0477209320435157, Accuracy: 0.4225, Time: 19.50 seconds\nEpoch 6/10, Loss: 1.0028444482729986, Accuracy: 0.4375, Time: 19.51 seconds\nEpoch 7/10, Loss: 0.9800334847890414, Accuracy: 0.4800, Time: 19.51 seconds\nEpoch 8/10, Loss: 0.9507822944567754, Accuracy: 0.5175, Time: 19.50 seconds\nEpoch 9/10, Loss: 0.9551844413463886, Accuracy: 0.5150, Time: 19.51 seconds\nEpoch 10/10, Loss: 0.9076725794718816, Accuracy: 0.5475, Time: 19.49 seconds\nValidation Trained Model Accuracy: 0.5450\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  500\nLabel 1: 157 samples\nLabel 0: 151 samples\nLabel 2: 192 samples\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.1006360799074173, Accuracy: 0.3900, Time: 24.36 seconds\nEpoch 2/10, Loss: 1.1052914895117283, Accuracy: 0.3780, Time: 24.38 seconds\nEpoch 3/10, Loss: 1.0937461629509926, Accuracy: 0.3860, Time: 24.42 seconds\nEpoch 4/10, Loss: 1.0696909949183464, Accuracy: 0.4120, Time: 24.42 seconds\nEpoch 5/10, Loss: 1.0656085163354874, Accuracy: 0.4240, Time: 24.42 seconds\nEpoch 6/10, Loss: 1.0495309010148048, Accuracy: 0.4460, Time: 24.40 seconds\nEpoch 7/10, Loss: 1.0351555161178112, Accuracy: 0.4200, Time: 24.41 seconds\nEpoch 8/10, Loss: 0.9998471289873123, Accuracy: 0.4420, Time: 24.41 seconds\nEpoch 9/10, Loss: 0.9740146659314632, Accuracy: 0.4940, Time: 24.43 seconds\nEpoch 10/10, Loss: 0.9696783497929573, Accuracy: 0.4860, Time: 24.41 seconds\nValidation Trained Model Accuracy: 0.5153\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  1000\nLabel 2: 391 samples\nLabel 0: 290 samples\nLabel 1: 319 samples\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.1157566085457802, Accuracy: 0.3650, Time: 48.69 seconds\nEpoch 2/10, Loss: 1.1201768442988396, Accuracy: 0.3520, Time: 48.73 seconds\nEpoch 3/10, Loss: 1.0888073593378067, Accuracy: 0.3910, Time: 48.76 seconds\nEpoch 4/10, Loss: 1.0820408929139376, Accuracy: 0.4000, Time: 48.75 seconds\nEpoch 5/10, Loss: 1.040732093155384, Accuracy: 0.4410, Time: 48.74 seconds\nEpoch 6/10, Loss: 0.9986618589609861, Accuracy: 0.4840, Time: 48.75 seconds\nEpoch 7/10, Loss: 0.9545777617022395, Accuracy: 0.5150, Time: 48.76 seconds\nEpoch 8/10, Loss: 0.908342182636261, Accuracy: 0.5680, Time: 48.75 seconds\nEpoch 9/10, Loss: 0.8552126847207546, Accuracy: 0.5910, Time: 48.76 seconds\nEpoch 10/10, Loss: 0.8398021534085274, Accuracy: 0.5990, Time: 48.77 seconds\nValidation Trained Model Accuracy: 0.6242\n===========================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,918,275 || all params: 340,063,238 || trainable%: 1.4463\nTraing Param:  base_model.classifier.modules_to_save.default.weight\nTraing Param:  base_model.classifier.modules_to_save.default.bias\nTraing Param:  prompt_encoder.default.embedding.weight\nTraining Data Length:  10000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Label 0: 2877 samples\nLabel 2: 4080 samples\nLabel 1: 3043 samples\n","output_type":"stream"}],"execution_count":null},{"id":"1e43f545","cell_type":"code","source":"\n#======================\nmodel = BertForSequenceClassification.from_pretrained(\n            \"bert-large-uncased\", num_labels=3).to(\"cuda\")\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        all_preds.extend(predictions.cpu().numpy())\n        all_labels.extend(batch['labels'].cpu().numpy())\n\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Base Model Accuracy: {accuracy:.4f}\")","metadata":{"papermill":{"duration":17.102177,"end_time":"2024-12-13T04:05:47.531244","exception":false,"start_time":"2024-12-13T04:05:30.429067","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T03:02:16.010560Z","iopub.status.idle":"2024-12-21T03:02:16.010893Z","shell.execute_reply.started":"2024-12-21T03:02:16.010746Z","shell.execute_reply":"2024-12-21T03:02:16.010763Z"}},"outputs":[],"execution_count":null}]}